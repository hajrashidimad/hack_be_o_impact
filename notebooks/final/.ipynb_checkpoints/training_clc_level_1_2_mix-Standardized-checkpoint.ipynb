{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:25:54.503903Z",
     "start_time": "2021-02-11T22:25:53.452686Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:25:55.282537Z",
     "start_time": "2021-02-11T22:25:54.511041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site</th>\n",
       "      <th>1dist</th>\n",
       "      <th>2dist</th>\n",
       "      <th>3dist</th>\n",
       "      <th>4dist</th>\n",
       "      <th>5dist</th>\n",
       "      <th>11dist</th>\n",
       "      <th>12dist</th>\n",
       "      <th>13dist</th>\n",
       "      <th>14dist</th>\n",
       "      <th>21dist</th>\n",
       "      <th>22dist</th>\n",
       "      <th>23dist</th>\n",
       "      <th>24dist</th>\n",
       "      <th>31dist</th>\n",
       "      <th>32dist</th>\n",
       "      <th>33dist</th>\n",
       "      <th>41dist</th>\n",
       "      <th>42dist</th>\n",
       "      <th>51dist</th>\n",
       "      <th>52dist</th>\n",
       "      <th>111dist</th>\n",
       "      <th>112dist</th>\n",
       "      <th>121dist</th>\n",
       "      <th>122dist</th>\n",
       "      <th>123dist</th>\n",
       "      <th>124dist</th>\n",
       "      <th>131dist</th>\n",
       "      <th>133dist</th>\n",
       "      <th>141dist</th>\n",
       "      <th>142dist</th>\n",
       "      <th>211dist</th>\n",
       "      <th>221dist</th>\n",
       "      <th>231dist</th>\n",
       "      <th>242dist</th>\n",
       "      <th>243dist</th>\n",
       "      <th>311dist</th>\n",
       "      <th>312dist</th>\n",
       "      <th>313dist</th>\n",
       "      <th>322dist</th>\n",
       "      <th>324dist</th>\n",
       "      <th>331dist</th>\n",
       "      <th>412dist</th>\n",
       "      <th>423dist</th>\n",
       "      <th>511dist</th>\n",
       "      <th>512dist</th>\n",
       "      <th>523dist</th>\n",
       "      <th>111surf</th>\n",
       "      <th>112surf</th>\n",
       "      <th>121surf</th>\n",
       "      <th>122surf</th>\n",
       "      <th>123surf</th>\n",
       "      <th>124surf</th>\n",
       "      <th>131surf</th>\n",
       "      <th>132</th>\n",
       "      <th>133surf</th>\n",
       "      <th>141surf</th>\n",
       "      <th>142surf</th>\n",
       "      <th>211surf</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>221surf</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>231surf</th>\n",
       "      <th>241</th>\n",
       "      <th>242surf</th>\n",
       "      <th>243surf</th>\n",
       "      <th>244</th>\n",
       "      <th>311surf</th>\n",
       "      <th>312surf</th>\n",
       "      <th>313surf</th>\n",
       "      <th>321</th>\n",
       "      <th>322surf</th>\n",
       "      <th>323</th>\n",
       "      <th>324surf</th>\n",
       "      <th>331surf</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "      <th>334</th>\n",
       "      <th>335</th>\n",
       "      <th>411</th>\n",
       "      <th>412surf</th>\n",
       "      <th>421</th>\n",
       "      <th>422</th>\n",
       "      <th>423surf</th>\n",
       "      <th>511surf</th>\n",
       "      <th>512surf</th>\n",
       "      <th>521</th>\n",
       "      <th>522</th>\n",
       "      <th>523surf</th>\n",
       "      <th>1surf</th>\n",
       "      <th>11surf</th>\n",
       "      <th>12surf</th>\n",
       "      <th>13surf</th>\n",
       "      <th>14surf</th>\n",
       "      <th>2surf</th>\n",
       "      <th>21surf</th>\n",
       "      <th>22surf</th>\n",
       "      <th>23surf</th>\n",
       "      <th>24surf</th>\n",
       "      <th>3surf</th>\n",
       "      <th>31surf</th>\n",
       "      <th>32surf</th>\n",
       "      <th>33surf</th>\n",
       "      <th>4surf</th>\n",
       "      <th>41surf</th>\n",
       "      <th>42surf</th>\n",
       "      <th>5surf</th>\n",
       "      <th>51surf</th>\n",
       "      <th>52surf</th>\n",
       "      <th>REF....SUBSTANCE</th>\n",
       "      <th>PERIOD</th>\n",
       "      <th>X6.benzylaminopurine</th>\n",
       "      <th>Aclonifen</th>\n",
       "      <th>Ametoctradin</th>\n",
       "      <th>Anthraquinone</th>\n",
       "      <th>Azoxystrobin</th>\n",
       "      <th>Benalaxyl</th>\n",
       "      <th>Boscalid</th>\n",
       "      <th>Captan</th>\n",
       "      <th>Carbendazim</th>\n",
       "      <th>Chlorothalonil</th>\n",
       "      <th>Chlorpropham</th>\n",
       "      <th>Chlorpyrifos.methyl</th>\n",
       "      <th>Clethodim</th>\n",
       "      <th>Cyflufenamid</th>\n",
       "      <th>Cymoxanil</th>\n",
       "      <th>Cyprodinil</th>\n",
       "      <th>Difenoconazole</th>\n",
       "      <th>Dimethomorph</th>\n",
       "      <th>Dimoxystrobin</th>\n",
       "      <th>Dodine</th>\n",
       "      <th>Ethofumesate</th>\n",
       "      <th>Fenoxycarb</th>\n",
       "      <th>Fenpropathrin</th>\n",
       "      <th>Fenpropimorph</th>\n",
       "      <th>Flonicamid</th>\n",
       "      <th>Fluazifop</th>\n",
       "      <th>Fluazinam</th>\n",
       "      <th>Fludioxonil</th>\n",
       "      <th>Fluopicolide</th>\n",
       "      <th>Fluopyram</th>\n",
       "      <th>Flupyradifurone</th>\n",
       "      <th>Flutolanil</th>\n",
       "      <th>Fluxapyroxad</th>\n",
       "      <th>Indoxacarb</th>\n",
       "      <th>Isofetamid</th>\n",
       "      <th>Metalaxyl</th>\n",
       "      <th>Metamitron</th>\n",
       "      <th>Methiocarb_total</th>\n",
       "      <th>Methoxyfenozide</th>\n",
       "      <th>Metobromuron</th>\n",
       "      <th>Metolachlor</th>\n",
       "      <th>Metrafenone</th>\n",
       "      <th>Penconazole</th>\n",
       "      <th>Pendimethalin</th>\n",
       "      <th>Phenmedipham</th>\n",
       "      <th>Phosmet</th>\n",
       "      <th>Pirimicarb</th>\n",
       "      <th>Prochloraz</th>\n",
       "      <th>Propyzamide</th>\n",
       "      <th>Prosulfocarb</th>\n",
       "      <th>Prothioconazole_d</th>\n",
       "      <th>Pyraclostrobin</th>\n",
       "      <th>Pyrimethanil</th>\n",
       "      <th>Quinoxyfen</th>\n",
       "      <th>Spinosad</th>\n",
       "      <th>Spirotetramat</th>\n",
       "      <th>Spiroxamine</th>\n",
       "      <th>Tau.fluvalinate</th>\n",
       "      <th>Tebuconazole</th>\n",
       "      <th>Tebufenozide</th>\n",
       "      <th>Tetraconazole</th>\n",
       "      <th>Thiabendazole</th>\n",
       "      <th>Thiacloprid</th>\n",
       "      <th>Thiophanate.methyl</th>\n",
       "      <th>Tri.allate</th>\n",
       "      <th>Trifloxystrobin</th>\n",
       "      <th>Zoxamide</th>\n",
       "      <th>Benfluralin</th>\n",
       "      <th>Benzovindiflupyr</th>\n",
       "      <th>Chlorantraniliprole</th>\n",
       "      <th>Coumaphos</th>\n",
       "      <th>Cyazofamid</th>\n",
       "      <th>Diphenylamine</th>\n",
       "      <th>Fenbuconazole</th>\n",
       "      <th>Fenpropidin</th>\n",
       "      <th>Nicosulfuron</th>\n",
       "      <th>Piperonylbutoxide</th>\n",
       "      <th>Prosulfuron</th>\n",
       "      <th>Simazine</th>\n",
       "      <th>Terbuthylazine</th>\n",
       "      <th>Deet</th>\n",
       "      <th>Dieldrin</th>\n",
       "      <th>Diflufenican</th>\n",
       "      <th>Epoxiconazole</th>\n",
       "      <th>Fenamidone</th>\n",
       "      <th>Mandipropamid</th>\n",
       "      <th>Propamocarb</th>\n",
       "      <th>Trifluralin</th>\n",
       "      <th>Cycloate</th>\n",
       "      <th>Pentachloroanisol</th>\n",
       "      <th>Propiconazole</th>\n",
       "      <th>Bupirimate</th>\n",
       "      <th>Etofenprox</th>\n",
       "      <th>Fenhexamid</th>\n",
       "      <th>Metconazole</th>\n",
       "      <th>Flucythrinate</th>\n",
       "      <th>Benthiavalicarb.iso</th>\n",
       "      <th>Cyflumetofen</th>\n",
       "      <th>Ethirimol</th>\n",
       "      <th>Imidacloprid</th>\n",
       "      <th>Propanil</th>\n",
       "      <th>Iprovalicarb</th>\n",
       "      <th>Hexaconazole</th>\n",
       "      <th>Methabenzthiazuron</th>\n",
       "      <th>Chlorotoluron</th>\n",
       "      <th>Propargite</th>\n",
       "      <th>Aldrin</th>\n",
       "      <th>Cyanofenphos</th>\n",
       "      <th>Cypermethrin</th>\n",
       "      <th>Pencycuron</th>\n",
       "      <th>X2.phenylphenol</th>\n",
       "      <th>Famoxadone</th>\n",
       "      <th>Tetradifon</th>\n",
       "      <th>Flufenacet</th>\n",
       "      <th>SEASON_x</th>\n",
       "      <th>Fungicide</th>\n",
       "      <th>Insecticide</th>\n",
       "      <th>Herbicide</th>\n",
       "      <th>Other_pesticides</th>\n",
       "      <th>LMR_Fungicide</th>\n",
       "      <th>LMR_Insecticide</th>\n",
       "      <th>LMR_Herbicide</th>\n",
       "      <th>LMR_Other_pesticides</th>\n",
       "      <th>Lead</th>\n",
       "      <th>Cadmium</th>\n",
       "      <th>Arsenic</th>\n",
       "      <th>Mercury</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Chrome</th>\n",
       "      <th>Zinc</th>\n",
       "      <th>SEASON_y</th>\n",
       "      <th>Limit_Lead</th>\n",
       "      <th>Limit_Cadmium</th>\n",
       "      <th>Limit_Arsenic</th>\n",
       "      <th>Limit_Mercury</th>\n",
       "      <th>Limit_Copper</th>\n",
       "      <th>Presence_Lead</th>\n",
       "      <th>Presence_Cadmium</th>\n",
       "      <th>Presence_Arsenic</th>\n",
       "      <th>Presence_Mercury</th>\n",
       "      <th>Presence_Copper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0012</td>\n",
       "      <td>491.383828</td>\n",
       "      <td>1087.774122</td>\n",
       "      <td>934.164041</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.262657</td>\n",
       "      <td>678.465668</td>\n",
       "      <td>117.220148</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1087.774122</td>\n",
       "      <td>934.164041</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.262657</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1020.033273</td>\n",
       "      <td>564.6098</td>\n",
       "      <td>117.220148</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1253.539431</td>\n",
       "      <td>922.008813</td>\n",
       "      <td>934.164041</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.262657</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>213419.497009</td>\n",
       "      <td>3.756405e+06</td>\n",
       "      <td>2.068585e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35584.844177</td>\n",
       "      <td>254819.361237</td>\n",
       "      <td>0</td>\n",
       "      <td>253441.670044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486328.326111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.038409e+06</td>\n",
       "      <td>3.969824e+06</td>\n",
       "      <td>2.068585e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290404.205414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290404.205414</td>\n",
       "      <td>253441.670044</td>\n",
       "      <td>253441.670044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486328.326111</td>\n",
       "      <td>486328.326111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B0012</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0012</td>\n",
       "      <td>491.383828</td>\n",
       "      <td>1087.774122</td>\n",
       "      <td>934.164041</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.262657</td>\n",
       "      <td>678.465668</td>\n",
       "      <td>117.220148</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1087.774122</td>\n",
       "      <td>934.164041</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.262657</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1020.033273</td>\n",
       "      <td>564.6098</td>\n",
       "      <td>117.220148</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1253.539431</td>\n",
       "      <td>922.008813</td>\n",
       "      <td>934.164041</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.262657</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>213419.497009</td>\n",
       "      <td>3.756405e+06</td>\n",
       "      <td>2.068585e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35584.844177</td>\n",
       "      <td>254819.361237</td>\n",
       "      <td>0</td>\n",
       "      <td>253441.670044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486328.326111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.038409e+06</td>\n",
       "      <td>3.969824e+06</td>\n",
       "      <td>2.068585e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290404.205414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290404.205414</td>\n",
       "      <td>253441.670044</td>\n",
       "      <td>253441.670044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486328.326111</td>\n",
       "      <td>486328.326111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B0012</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.11</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0012</td>\n",
       "      <td>491.383828</td>\n",
       "      <td>1087.774122</td>\n",
       "      <td>934.164041</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.262657</td>\n",
       "      <td>678.465668</td>\n",
       "      <td>117.220148</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1087.774122</td>\n",
       "      <td>934.164041</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.262657</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1020.033273</td>\n",
       "      <td>564.6098</td>\n",
       "      <td>117.220148</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1253.539431</td>\n",
       "      <td>922.008813</td>\n",
       "      <td>934.164041</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.262657</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>213419.497009</td>\n",
       "      <td>3.756405e+06</td>\n",
       "      <td>2.068585e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35584.844177</td>\n",
       "      <td>254819.361237</td>\n",
       "      <td>0</td>\n",
       "      <td>253441.670044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486328.326111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.038409e+06</td>\n",
       "      <td>3.969824e+06</td>\n",
       "      <td>2.068585e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290404.205414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290404.205414</td>\n",
       "      <td>253441.670044</td>\n",
       "      <td>253441.670044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486328.326111</td>\n",
       "      <td>486328.326111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B0012</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.14</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0012</td>\n",
       "      <td>491.383828</td>\n",
       "      <td>1087.774122</td>\n",
       "      <td>934.164041</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.262657</td>\n",
       "      <td>678.465668</td>\n",
       "      <td>117.220148</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1087.774122</td>\n",
       "      <td>934.164041</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.262657</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1020.033273</td>\n",
       "      <td>564.6098</td>\n",
       "      <td>117.220148</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1253.539431</td>\n",
       "      <td>922.008813</td>\n",
       "      <td>934.164041</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.262657</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>213419.497009</td>\n",
       "      <td>3.756405e+06</td>\n",
       "      <td>2.068585e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35584.844177</td>\n",
       "      <td>254819.361237</td>\n",
       "      <td>0</td>\n",
       "      <td>253441.670044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486328.326111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.038409e+06</td>\n",
       "      <td>3.969824e+06</td>\n",
       "      <td>2.068585e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290404.205414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290404.205414</td>\n",
       "      <td>253441.670044</td>\n",
       "      <td>253441.670044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486328.326111</td>\n",
       "      <td>486328.326111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B0012</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0012</td>\n",
       "      <td>491.383828</td>\n",
       "      <td>1087.774122</td>\n",
       "      <td>934.164041</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.262657</td>\n",
       "      <td>678.465668</td>\n",
       "      <td>117.220148</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1087.774122</td>\n",
       "      <td>934.164041</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.262657</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1020.033273</td>\n",
       "      <td>564.6098</td>\n",
       "      <td>117.220148</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1253.539431</td>\n",
       "      <td>922.008813</td>\n",
       "      <td>934.164041</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.262657</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>213419.497009</td>\n",
       "      <td>3.756405e+06</td>\n",
       "      <td>2.068585e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35584.844177</td>\n",
       "      <td>254819.361237</td>\n",
       "      <td>0</td>\n",
       "      <td>253441.670044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486328.326111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.038409e+06</td>\n",
       "      <td>3.969824e+06</td>\n",
       "      <td>2.068585e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290404.205414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>290404.205414</td>\n",
       "      <td>253441.670044</td>\n",
       "      <td>253441.670044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486328.326111</td>\n",
       "      <td>486328.326111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B0012</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Site       1dist        2dist       3dist  4dist      5dist      11dist      12dist  13dist  14dist  21dist  22dist  23dist       24dist      31dist  32dist  33dist  41dist  42dist     51dist  52dist      111dist   112dist     121dist  122dist  123dist  124dist  131dist  133dist  141dist  142dist  211dist  221dist  231dist      242dist     243dist     311dist  312dist  313dist  322dist  324dist  331dist  412dist  423dist    511dist  512dist  523dist        111surf       112surf       121surf  122surf  123surf  124surf  131surf  132  133surf  141surf  142surf  211surf  212  213  221surf  222  223  231surf  241       242surf        243surf  244        311surf  312surf  313surf  321  322surf  323  324surf  331surf  332  333  334  335  411  412surf  421  422  423surf        511surf  512surf  521  522  523surf         1surf        11surf        12surf  13surf  14surf          2surf  21surf  22surf  23surf         24surf          3surf         31surf  32surf  33surf  4surf  41surf  \\\n",
       "0  B0012  491.383828  1087.774122  934.164041   -1.0  55.262657  678.465668  117.220148    -1.0    -1.0    -1.0    -1.0    -1.0  1087.774122  934.164041    -1.0    -1.0    -1.0    -1.0  55.262657    -1.0  1020.033273  564.6098  117.220148     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0  1253.539431  922.008813  934.164041     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0  55.262657     -1.0     -1.0  213419.497009  3.756405e+06  2.068585e+06      0.0      0.0      0.0      0.0    0      0.0      0.0      0.0      0.0    0    0      0.0    0    0      0.0    0  35584.844177  254819.361237    0  253441.670044      0.0      0.0    0      0.0    0      0.0      0.0    0    0    0    0    0      0.0    0    0      0.0  486328.326111      0.0    0    0      0.0  6.038409e+06  3.969824e+06  2.068585e+06     0.0     0.0  290404.205414     0.0     0.0     0.0  290404.205414  253441.670044  253441.670044     0.0     0.0    0.0     0.0   \n",
       "1  B0012  491.383828  1087.774122  934.164041   -1.0  55.262657  678.465668  117.220148    -1.0    -1.0    -1.0    -1.0    -1.0  1087.774122  934.164041    -1.0    -1.0    -1.0    -1.0  55.262657    -1.0  1020.033273  564.6098  117.220148     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0  1253.539431  922.008813  934.164041     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0  55.262657     -1.0     -1.0  213419.497009  3.756405e+06  2.068585e+06      0.0      0.0      0.0      0.0    0      0.0      0.0      0.0      0.0    0    0      0.0    0    0      0.0    0  35584.844177  254819.361237    0  253441.670044      0.0      0.0    0      0.0    0      0.0      0.0    0    0    0    0    0      0.0    0    0      0.0  486328.326111      0.0    0    0      0.0  6.038409e+06  3.969824e+06  2.068585e+06     0.0     0.0  290404.205414     0.0     0.0     0.0  290404.205414  253441.670044  253441.670044     0.0     0.0    0.0     0.0   \n",
       "2  B0012  491.383828  1087.774122  934.164041   -1.0  55.262657  678.465668  117.220148    -1.0    -1.0    -1.0    -1.0    -1.0  1087.774122  934.164041    -1.0    -1.0    -1.0    -1.0  55.262657    -1.0  1020.033273  564.6098  117.220148     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0  1253.539431  922.008813  934.164041     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0  55.262657     -1.0     -1.0  213419.497009  3.756405e+06  2.068585e+06      0.0      0.0      0.0      0.0    0      0.0      0.0      0.0      0.0    0    0      0.0    0    0      0.0    0  35584.844177  254819.361237    0  253441.670044      0.0      0.0    0      0.0    0      0.0      0.0    0    0    0    0    0      0.0    0    0      0.0  486328.326111      0.0    0    0      0.0  6.038409e+06  3.969824e+06  2.068585e+06     0.0     0.0  290404.205414     0.0     0.0     0.0  290404.205414  253441.670044  253441.670044     0.0     0.0    0.0     0.0   \n",
       "3  B0012  491.383828  1087.774122  934.164041   -1.0  55.262657  678.465668  117.220148    -1.0    -1.0    -1.0    -1.0    -1.0  1087.774122  934.164041    -1.0    -1.0    -1.0    -1.0  55.262657    -1.0  1020.033273  564.6098  117.220148     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0  1253.539431  922.008813  934.164041     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0  55.262657     -1.0     -1.0  213419.497009  3.756405e+06  2.068585e+06      0.0      0.0      0.0      0.0    0      0.0      0.0      0.0      0.0    0    0      0.0    0    0      0.0    0  35584.844177  254819.361237    0  253441.670044      0.0      0.0    0      0.0    0      0.0      0.0    0    0    0    0    0      0.0    0    0      0.0  486328.326111      0.0    0    0      0.0  6.038409e+06  3.969824e+06  2.068585e+06     0.0     0.0  290404.205414     0.0     0.0     0.0  290404.205414  253441.670044  253441.670044     0.0     0.0    0.0     0.0   \n",
       "4  B0012  491.383828  1087.774122  934.164041   -1.0  55.262657  678.465668  117.220148    -1.0    -1.0    -1.0    -1.0    -1.0  1087.774122  934.164041    -1.0    -1.0    -1.0    -1.0  55.262657    -1.0  1020.033273  564.6098  117.220148     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0  1253.539431  922.008813  934.164041     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0     -1.0  55.262657     -1.0     -1.0  213419.497009  3.756405e+06  2.068585e+06      0.0      0.0      0.0      0.0    0      0.0      0.0      0.0      0.0    0    0      0.0    0    0      0.0    0  35584.844177  254819.361237    0  253441.670044      0.0      0.0    0      0.0    0      0.0      0.0    0    0    0    0    0      0.0    0    0      0.0  486328.326111      0.0    0    0      0.0  6.038409e+06  3.969824e+06  2.068585e+06     0.0     0.0  290404.205414     0.0     0.0     0.0  290404.205414  253441.670044  253441.670044     0.0     0.0    0.0     0.0   \n",
       "\n",
       "   42surf          5surf         51surf  52surf REF....SUBSTANCE  PERIOD  X6.benzylaminopurine  Aclonifen  Ametoctradin  Anthraquinone  Azoxystrobin  Benalaxyl  Boscalid  Captan  Carbendazim  Chlorothalonil  Chlorpropham  Chlorpyrifos.methyl  Clethodim  Cyflufenamid  Cymoxanil  Cyprodinil  Difenoconazole  Dimethomorph  Dimoxystrobin  Dodine  Ethofumesate  Fenoxycarb  Fenpropathrin  Fenpropimorph  Flonicamid  Fluazifop  Fluazinam  Fludioxonil  Fluopicolide  Fluopyram  Flupyradifurone  Flutolanil  Fluxapyroxad  Indoxacarb  Isofetamid  Metalaxyl  Metamitron  Methiocarb_total  Methoxyfenozide  Metobromuron  Metolachlor  Metrafenone  Penconazole  Pendimethalin  Phenmedipham  Phosmet  Pirimicarb  Prochloraz  Propyzamide  Prosulfocarb  Prothioconazole_d  Pyraclostrobin  Pyrimethanil  Quinoxyfen  Spinosad  Spirotetramat  Spiroxamine  Tau.fluvalinate  Tebuconazole  Tebufenozide  Tetraconazole  Thiabendazole  Thiacloprid  Thiophanate.methyl  Tri.allate  Trifloxystrobin  Zoxamide  Benfluralin  \\\n",
       "0     0.0  486328.326111  486328.326111     0.0            B0012  2020.0                   0.0     0.0048           0.0            0.0           0.0        0.0       0.0   0.270          0.0          0.0000           0.0                  0.0        0.0           0.0        0.0         0.0             0.0           0.0            0.0     0.0           0.0         0.0            0.0            0.0         0.0        0.0        0.0          0.0           0.0        0.0              0.0         0.0           0.0         0.0         0.0        0.0         0.0               0.0              0.0           0.0          0.0          0.0          0.0            0.0           0.0      0.0         0.0         0.0          0.0           0.0                0.0             0.0           0.0         0.0       0.0            0.0          0.0              0.0           0.0           0.0            0.0            0.0          0.0                 0.0         0.0              0.0       0.0          0.0   \n",
       "1     0.0  486328.326111  486328.326111     0.0            B0012  2020.0                   0.0     0.0048           0.0            0.0           0.0        0.0       0.0   0.270          0.0          0.0000           0.0                  0.0        0.0           0.0        0.0         0.0             0.0           0.0            0.0     0.0           0.0         0.0            0.0            0.0         0.0        0.0        0.0          0.0           0.0        0.0              0.0         0.0           0.0         0.0         0.0        0.0         0.0               0.0              0.0           0.0          0.0          0.0          0.0            0.0           0.0      0.0         0.0         0.0          0.0           0.0                0.0             0.0           0.0         0.0       0.0            0.0          0.0              0.0           0.0           0.0            0.0            0.0          0.0                 0.0         0.0              0.0       0.0          0.0   \n",
       "2     0.0  486328.326111  486328.326111     0.0            B0012  2020.0                   0.0     0.0048           0.0            0.0           0.0        0.0       0.0   0.270          0.0          0.0000           0.0                  0.0        0.0           0.0        0.0         0.0             0.0           0.0            0.0     0.0           0.0         0.0            0.0            0.0         0.0        0.0        0.0          0.0           0.0        0.0              0.0         0.0           0.0         0.0         0.0        0.0         0.0               0.0              0.0           0.0          0.0          0.0          0.0            0.0           0.0      0.0         0.0         0.0          0.0           0.0                0.0             0.0           0.0         0.0       0.0            0.0          0.0              0.0           0.0           0.0            0.0            0.0          0.0                 0.0         0.0              0.0       0.0          0.0   \n",
       "3     0.0  486328.326111  486328.326111     0.0            B0012  2020.0                   0.0     0.0048           0.0            0.0           0.0        0.0       0.0   0.270          0.0          0.0000           0.0                  0.0        0.0           0.0        0.0         0.0             0.0           0.0            0.0     0.0           0.0         0.0            0.0            0.0         0.0        0.0        0.0          0.0           0.0        0.0              0.0         0.0           0.0         0.0         0.0        0.0         0.0               0.0              0.0           0.0          0.0          0.0          0.0            0.0           0.0      0.0         0.0         0.0          0.0           0.0                0.0             0.0           0.0         0.0       0.0            0.0          0.0              0.0           0.0           0.0            0.0            0.0          0.0                 0.0         0.0              0.0       0.0          0.0   \n",
       "4     0.0  486328.326111  486328.326111     0.0            B0012  2020.0                   0.0     0.0000           0.0            0.0           0.0        0.0       0.0   0.019          0.0          0.0072           0.0                  0.0        0.0           0.0        0.0         0.0             0.0           0.0            0.0     0.0           0.0         0.0            0.0            0.0         0.0        0.0        0.0          0.0           0.0        0.0              0.0         0.0           0.0         0.0         0.0        0.0         0.0               0.0              0.0           0.0          0.0          0.0          0.0            0.0           0.0      0.0         0.0         0.0          0.0           0.0                0.0             0.0           0.0         0.0       0.0            0.0          0.0              0.0           0.0           0.0            0.0            0.0          0.0                 0.0         0.0              0.0       0.0          0.0   \n",
       "\n",
       "   Benzovindiflupyr  Chlorantraniliprole  Coumaphos  Cyazofamid  Diphenylamine  Fenbuconazole  Fenpropidin  Nicosulfuron  Piperonylbutoxide  Prosulfuron  Simazine  Terbuthylazine  Deet  Dieldrin  Diflufenican  Epoxiconazole  Fenamidone  Mandipropamid  Propamocarb  Trifluralin  Cycloate  Pentachloroanisol  Propiconazole  Bupirimate  Etofenprox  Fenhexamid  Metconazole  Flucythrinate  Benthiavalicarb.iso  Cyflumetofen  Ethirimol  Imidacloprid  Propanil  Iprovalicarb  Hexaconazole  Methabenzthiazuron  Chlorotoluron  Propargite  Aldrin  Cyanofenphos  Cypermethrin  Pencycuron  X2.phenylphenol  Famoxadone  Tetradifon  Flufenacet SEASON_x  Fungicide  Insecticide  Herbicide  Other_pesticides  LMR_Fungicide  LMR_Insecticide  LMR_Herbicide  LMR_Other_pesticides  Lead  Cadmium  Arsenic  Mercury  Copper  Chrome  Zinc  SEASON_y Limit_Lead Limit_Cadmium Limit_Arsenic Limit_Mercury Limit_Copper Presence_Lead Presence_Cadmium Presence_Arsenic Presence_Mercury Presence_Copper  \n",
       "0               0.0                  0.0        0.0         0.0            0.0            0.0          0.0           0.0                0.0          0.0       0.0             0.0   0.0       0.0           0.0            0.0         0.0            0.0          0.0          0.0       0.0                0.0            0.0         0.0         0.0         0.0          0.0            0.0                  0.0           0.0        0.0           0.0       0.0           0.0           0.0                 0.0            0.0         0.0     0.0           0.0           0.0         0.0              0.0         0.0         0.0         0.0       P1        1.0          0.0        1.0               0.0            1.0              0.0            0.0                   0.0  0.88     0.29    0.048      0.0    11.0    0.14  51.0       0.0      False         False         False         False        False          True             True             True            False            True  \n",
       "1               0.0                  0.0        0.0         0.0            0.0            0.0          0.0           0.0                0.0          0.0       0.0             0.0   0.0       0.0           0.0            0.0         0.0            0.0          0.0          0.0       0.0                0.0            0.0         0.0         0.0         0.0          0.0            0.0                  0.0           0.0        0.0           0.0       0.0           0.0           0.0                 0.0            0.0         0.0     0.0           0.0           0.0         0.0              0.0         0.0         0.0         0.0       P1        1.0          0.0        1.0               0.0            1.0              0.0            0.0                   0.0  0.65     0.23    0.000      0.0     8.7    0.11  48.0       1.0      False         False         False         False        False          True             True            False            False            True  \n",
       "2               0.0                  0.0        0.0         0.0            0.0            0.0          0.0           0.0                0.0          0.0       0.0             0.0   0.0       0.0           0.0            0.0         0.0            0.0          0.0          0.0       0.0                0.0            0.0         0.0         0.0         0.0          0.0            0.0                  0.0           0.0        0.0           0.0       0.0           0.0           0.0                 0.0            0.0         0.0     0.0           0.0           0.0         0.0              0.0         0.0         0.0         0.0       P1        1.0          0.0        1.0               0.0            1.0              0.0            0.0                   0.0  0.89     0.16    0.059      0.0     7.2    0.14  43.0       2.0      False         False         False         False        False          True             True             True            False            True  \n",
       "3               0.0                  0.0        0.0         0.0            0.0            0.0          0.0           0.0                0.0          0.0       0.0             0.0   0.0       0.0           0.0            0.0         0.0            0.0          0.0          0.0       0.0                0.0            0.0         0.0         0.0         0.0          0.0            0.0                  0.0           0.0        0.0           0.0       0.0           0.0           0.0                 0.0            0.0         0.0     0.0           0.0           0.0         0.0              0.0         0.0         0.0         0.0       P1        1.0          0.0        1.0               0.0            1.0              0.0            0.0                   0.0  0.63     0.64    0.053      0.0     9.1    0.16  40.0       3.0      False         False         False         False        False          True             True             True            False            True  \n",
       "4               0.0                  0.0        0.0         0.0            0.0            0.0          0.0           0.0                0.0          0.0       0.0             0.0   0.0       0.0           0.0            0.0         0.0            0.0          0.0          0.0       0.0                0.0            0.0         0.0         0.0         0.0          0.0            0.0                  0.0           0.0        0.0           0.0       0.0           0.0           0.0                 0.0            0.0         0.0     0.0           0.0           0.0         0.0              0.0         0.0         0.0         0.0       P2        2.0          0.0        0.0               0.0            0.0              0.0            0.0                   0.0  0.88     0.29    0.048      0.0    11.0    0.14  51.0       0.0      False         False         False         False        False          True             True             True            False            True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/final/data_final.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Used data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:25:55.513687Z",
     "start_time": "2021-02-11T22:25:55.301991Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>11dist</th>\n",
       "      <th>12dist</th>\n",
       "      <th>13dist</th>\n",
       "      <th>14dist</th>\n",
       "      <th>21dist</th>\n",
       "      <th>22dist</th>\n",
       "      <th>23dist</th>\n",
       "      <th>24dist</th>\n",
       "      <th>31dist</th>\n",
       "      <th>32dist</th>\n",
       "      <th>33dist</th>\n",
       "      <th>4dist</th>\n",
       "      <th>5dist</th>\n",
       "      <th>11surf</th>\n",
       "      <th>12surf</th>\n",
       "      <th>13surf</th>\n",
       "      <th>14surf</th>\n",
       "      <th>21surf</th>\n",
       "      <th>22surf</th>\n",
       "      <th>23surf</th>\n",
       "      <th>24surf</th>\n",
       "      <th>31surf</th>\n",
       "      <th>32surf</th>\n",
       "      <th>33surf</th>\n",
       "      <th>4surf</th>\n",
       "      <th>5surf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>678.465668</td>\n",
       "      <td>117.220148</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1087.774122</td>\n",
       "      <td>934.164041</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.262657</td>\n",
       "      <td>3.969824e+06</td>\n",
       "      <td>2.068585e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>290404.205414</td>\n",
       "      <td>253441.670044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486328.326111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>678.465668</td>\n",
       "      <td>117.220148</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1087.774122</td>\n",
       "      <td>934.164041</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.262657</td>\n",
       "      <td>3.969824e+06</td>\n",
       "      <td>2.068585e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>290404.205414</td>\n",
       "      <td>253441.670044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486328.326111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>678.465668</td>\n",
       "      <td>117.220148</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1087.774122</td>\n",
       "      <td>934.164041</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.262657</td>\n",
       "      <td>3.969824e+06</td>\n",
       "      <td>2.068585e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>290404.205414</td>\n",
       "      <td>253441.670044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486328.326111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>678.465668</td>\n",
       "      <td>117.220148</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1087.774122</td>\n",
       "      <td>934.164041</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.262657</td>\n",
       "      <td>3.969824e+06</td>\n",
       "      <td>2.068585e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>290404.205414</td>\n",
       "      <td>253441.670044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486328.326111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>678.465668</td>\n",
       "      <td>117.220148</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1087.774122</td>\n",
       "      <td>934.164041</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.262657</td>\n",
       "      <td>3.969824e+06</td>\n",
       "      <td>2.068585e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>290404.205414</td>\n",
       "      <td>253441.670044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486328.326111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>559.127486</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>38.517189</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>959.229801</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.066819e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.691564e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.750705e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>219632.734863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>559.127486</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>38.517189</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>959.229801</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.066819e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.691564e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.750705e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>219632.734863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>559.127486</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>38.517189</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>959.229801</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.066819e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.691564e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.750705e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>219632.734863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>559.127486</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>38.517189</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>959.229801</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.066819e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.691564e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.750705e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>219632.734863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>559.127486</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>38.517189</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>959.229801</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.066819e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.691564e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.750705e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>219632.734863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1486 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          11dist      12dist  13dist  14dist      21dist  22dist     23dist       24dist      31dist  32dist  33dist  4dist      5dist        11surf        12surf  13surf  14surf        21surf  22surf        23surf         24surf         31surf  32surf  33surf  4surf          5surf\n",
       "0     678.465668  117.220148    -1.0    -1.0   -1.000000    -1.0  -1.000000  1087.774122  934.164041    -1.0    -1.0   -1.0  55.262657  3.969824e+06  2.068585e+06     0.0     0.0  0.000000e+00     0.0  0.000000e+00  290404.205414  253441.670044     0.0     0.0    0.0  486328.326111\n",
       "1     678.465668  117.220148    -1.0    -1.0   -1.000000    -1.0  -1.000000  1087.774122  934.164041    -1.0    -1.0   -1.0  55.262657  3.969824e+06  2.068585e+06     0.0     0.0  0.000000e+00     0.0  0.000000e+00  290404.205414  253441.670044     0.0     0.0    0.0  486328.326111\n",
       "2     678.465668  117.220148    -1.0    -1.0   -1.000000    -1.0  -1.000000  1087.774122  934.164041    -1.0    -1.0   -1.0  55.262657  3.969824e+06  2.068585e+06     0.0     0.0  0.000000e+00     0.0  0.000000e+00  290404.205414  253441.670044     0.0     0.0    0.0  486328.326111\n",
       "3     678.465668  117.220148    -1.0    -1.0   -1.000000    -1.0  -1.000000  1087.774122  934.164041    -1.0    -1.0   -1.0  55.262657  3.969824e+06  2.068585e+06     0.0     0.0  0.000000e+00     0.0  0.000000e+00  290404.205414  253441.670044     0.0     0.0    0.0  486328.326111\n",
       "4     678.465668  117.220148    -1.0    -1.0   -1.000000    -1.0  -1.000000  1087.774122  934.164041    -1.0    -1.0   -1.0  55.262657  3.969824e+06  2.068585e+06     0.0     0.0  0.000000e+00     0.0  0.000000e+00  290404.205414  253441.670044     0.0     0.0    0.0  486328.326111\n",
       "...          ...         ...     ...     ...         ...     ...        ...          ...         ...     ...     ...    ...        ...           ...           ...     ...     ...           ...     ...           ...            ...            ...     ...     ...    ...            ...\n",
       "1481    0.000000   -1.000000    -1.0    -1.0  559.127486    -1.0  38.517189    -1.000000  959.229801    -1.0    -1.0   -1.0  -1.000000  4.066819e+05  0.000000e+00     0.0     0.0  2.691564e+06     0.0  3.750705e+06       0.000000  219632.734863     0.0     0.0    0.0       0.000000\n",
       "1482    0.000000   -1.000000    -1.0    -1.0  559.127486    -1.0  38.517189    -1.000000  959.229801    -1.0    -1.0   -1.0  -1.000000  4.066819e+05  0.000000e+00     0.0     0.0  2.691564e+06     0.0  3.750705e+06       0.000000  219632.734863     0.0     0.0    0.0       0.000000\n",
       "1483    0.000000   -1.000000    -1.0    -1.0  559.127486    -1.0  38.517189    -1.000000  959.229801    -1.0    -1.0   -1.0  -1.000000  4.066819e+05  0.000000e+00     0.0     0.0  2.691564e+06     0.0  3.750705e+06       0.000000  219632.734863     0.0     0.0    0.0       0.000000\n",
       "1484    0.000000   -1.000000    -1.0    -1.0  559.127486    -1.0  38.517189    -1.000000  959.229801    -1.0    -1.0   -1.0  -1.000000  4.066819e+05  0.000000e+00     0.0     0.0  2.691564e+06     0.0  3.750705e+06       0.000000  219632.734863     0.0     0.0    0.0       0.000000\n",
       "1485    0.000000   -1.000000    -1.0    -1.0  559.127486    -1.0  38.517189    -1.000000  959.229801    -1.0    -1.0   -1.0  -1.000000  4.066819e+05  0.000000e+00     0.0     0.0  2.691564e+06     0.0  3.750705e+06       0.000000  219632.734863     0.0     0.0    0.0       0.000000\n",
       "\n",
       "[1486 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_features = [\n",
    "    '11dist','12dist', '13dist', '14dist',\n",
    "    '21dist', '22dist', '23dist', '24dist',\n",
    "    '31dist', '32dist', '33dist',\n",
    "    '4dist',\n",
    "    '5dist',\n",
    "    '11surf', '12surf', '13surf', '14surf',\n",
    "    '21surf', '22surf', '23surf', '24surf',\n",
    "    '31surf', '32surf', '33surf', \n",
    "    '4surf',\n",
    "    '5surf'\n",
    "]\n",
    "\n",
    "X = df[columns_features]\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:25:57.865539Z",
     "start_time": "2021-02-11T22:25:55.532082Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:25:57.882573Z",
     "start_time": "2021-02-11T22:25:57.875005Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_val_test(clf, X_data, y_data):\n",
    "    scores = cross_val_score(clf, X_data, y_data, cv=5)\n",
    "    print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "    print('----------', scores, '---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:25:57.936839Z",
     "start_time": "2021-02-11T22:25:57.896255Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_forest_test(X_data, y_data):\n",
    "    print(\"Random Forest\")\n",
    "    clf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "    cross_val_test(clf, X_data, y_data)\n",
    "    \n",
    "def knn_test(X_data, y_data):\n",
    "    print(\"KNN\")\n",
    "    clf = KNeighborsClassifier(3)\n",
    "    cross_val_test(clf, X_data, y_data)\n",
    "    \n",
    "def decision_tree_test(X_data, y_data):\n",
    "    print(\"Decision Tree\")\n",
    "    clf = DecisionTreeClassifier(max_depth=5)\n",
    "    cross_val_test(clf, X_data, y_data)\n",
    "\n",
    "def svc_linear_test(X_data, y_data):\n",
    "    print(\"SVC Linear\")\n",
    "    clf = SVC(kernel=\"linear\", C=0.025)\n",
    "    cross_val_test(clf, X_data, y_data)\n",
    "\n",
    "def svc_gamma_test(X_data, y_data):\n",
    "    print(\"SVC Gamma\")\n",
    "    clf = SVC(gamma=2, C=1)\n",
    "    cross_val_test(clf, X_data, y_data)\n",
    "\n",
    "def gaussian_process_test(X_data, y_data):\n",
    "    print(\"Gaussian Process\")\n",
    "    clf = GaussianProcessClassifier(1.0 * RBF(1.0))\n",
    "    cross_val_test(clf, X_data, y_data)\n",
    "\n",
    "def mlp_cross_test(X_data, y_data):\n",
    "    print(\"MLP\")\n",
    "    clf = MLPClassifier(alpha=1, max_iter=1000)\n",
    "    cross_val_test(clf, X_data, y_data)\n",
    "\n",
    "def ada_boost_test(X_data, y_data):\n",
    "    print(\"Ada Boost\")\n",
    "    clf = AdaBoostClassifier()\n",
    "    cross_val_test(clf, X_data, y_data)\n",
    "\n",
    "def gaussian_nb_test(X_data, y_data):\n",
    "    print(\"Gaussian NB\")\n",
    "    clf = GaussianNB()\n",
    "    cross_val_test(clf, X_data, y_data)\n",
    "\n",
    "def quadratic_discriminant_analasys_test(X_data, y_data):\n",
    "    print(\"Quadratic Discriminant Analysis\")\n",
    "    clf = QuadraticDiscriminantAnalysis()\n",
    "    cross_val_test(clf, X_data, y_data)\n",
    "\n",
    "    \n",
    "# LAUNCH ALL VALIDATION \n",
    "def full_cross_validation(X_data, y_data):\n",
    "    random_forest_test(X_data, y_data)\n",
    "    knn_test(X_data, y_data)\n",
    "    decision_tree_test(X_data, y_data)\n",
    "    svc_linear_test(X_data, y_data)\n",
    "    svc_gamma_test(X_data, y_data)\n",
    "    # TO SLOW - gaussian_process_test(X_data, y_data)\n",
    "    mlp_cross_test(X_data, y_data)\n",
    "    ada_boost_test(X_data, y_data)\n",
    "    gaussian_nb_test(X_data, y_data)\n",
    "    quadratic_discriminant_analasys_test(X_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pesticides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Present or Not Present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1.1 - Global pesticide presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:26:03.118504Z",
     "start_time": "2021-02-11T22:25:57.960539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.56 accuracy with a standard deviation of 0.09\n",
      "---------- [0.66778523 0.62626263 0.4040404  0.51515152 0.58249158] ---------\n",
      "KNN\n",
      "0.50 accuracy with a standard deviation of 0.07\n",
      "---------- [0.54026846 0.58922559 0.3973064  0.45454545 0.50841751] ---------\n",
      "Decision Tree\n",
      "0.51 accuracy with a standard deviation of 0.10\n",
      "---------- [0.54697987 0.58922559 0.35353535 0.44781145 0.61616162] ---------\n",
      "MLP\n",
      "0.51 accuracy with a standard deviation of 0.08\n",
      "---------- [0.55369128 0.62962963 0.47811448 0.4006734  0.5016835 ] ---------\n",
      "Ada Boost\n",
      "0.48 accuracy with a standard deviation of 0.09\n",
      "---------- [0.43288591 0.58922559 0.3973064  0.39393939 0.58249158] ---------\n",
      "Gaussian NB\n",
      "0.55 accuracy with a standard deviation of 0.05\n",
      "---------- [0.55369128 0.51515152 0.53872054 0.48821549 0.63973064] ---------\n",
      "Quadratic Discriminant Analysis\n",
      "0.47 accuracy with a standard deviation of 0.06\n",
      "---------- [0.55369128 0.51515152 0.44781145 0.38047138 0.46801347] ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "target = (df['Fungicide'] + df['Insecticide'] + df['Herbicide'] + df['Other_pesticides']) > 0\n",
    "full_cross_validation(X, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1.2 - Fungicide presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:26:07.998720Z",
     "start_time": "2021-02-11T22:26:03.130045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.47 accuracy with a standard deviation of 0.08\n",
      "---------- [0.53020134 0.58585859 0.39393939 0.37373737 0.48148148] ---------\n",
      "KNN\n",
      "0.46 accuracy with a standard deviation of 0.08\n",
      "---------- [0.48993289 0.48484848 0.34680135 0.4040404  0.58585859] ---------\n",
      "Decision Tree\n",
      "0.50 accuracy with a standard deviation of 0.11\n",
      "---------- [0.63758389 0.54545455 0.34006734 0.40740741 0.56228956] ---------\n",
      "MLP\n",
      "0.47 accuracy with a standard deviation of 0.09\n",
      "---------- [0.47651007 0.5959596  0.34006734 0.41750842 0.51515152] ---------\n",
      "Ada Boost\n",
      "0.46 accuracy with a standard deviation of 0.09\n",
      "---------- [0.4295302  0.56565657 0.35016835 0.37373737 0.55892256] ---------\n",
      "Gaussian NB\n",
      "0.53 accuracy with a standard deviation of 0.09\n",
      "---------- [0.61744966 0.48484848 0.49158249 0.41750842 0.65319865] ---------\n",
      "Quadratic Discriminant Analysis\n",
      "0.46 accuracy with a standard deviation of 0.09\n",
      "---------- [0.54362416 0.48484848 0.36700337 0.36026936 0.56565657] ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "target = (df['Fungicide']) > 0\n",
    "full_cross_validation(X, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1.3 - Insecticide presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:26:13.460859Z",
     "start_time": "2021-02-11T22:26:08.005239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.80 accuracy with a standard deviation of 0.11\n",
      "---------- [0.89261745 0.59259259 0.8956229  0.81481481 0.7979798 ] ---------\n",
      "KNN\n",
      "0.55 accuracy with a standard deviation of 0.23\n",
      "---------- [0.89261745 0.43097643 0.65319865 0.20875421 0.56902357] ---------\n",
      "Decision Tree\n",
      "0.63 accuracy with a standard deviation of 0.16\n",
      "---------- [0.89261745 0.43097643 0.54208754 0.67676768 0.58585859] ---------\n",
      "MLP\n",
      "0.55 accuracy with a standard deviation of 0.15\n",
      "---------- [0.73825503 0.42424242 0.65319865 0.34006734 0.5993266 ] ---------\n",
      "Ada Boost\n",
      "0.55 accuracy with a standard deviation of 0.21\n",
      "---------- [0.89261745 0.43097643 0.66329966 0.25589226 0.53198653] ---------\n",
      "Gaussian NB\n",
      "0.49 accuracy with a standard deviation of 0.20\n",
      "---------- [0.5704698  0.47138047 0.12794613 0.54208754 0.75084175] ---------\n",
      "Quadratic Discriminant Analysis\n",
      "0.50 accuracy with a standard deviation of 0.12\n",
      "---------- [0.62416107 0.41750842 0.64309764 0.34343434 0.48484848] ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "target = (df['Insecticide']) > 0\n",
    "full_cross_validation(X, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1.4 - Herbicide presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:26:18.415033Z",
     "start_time": "2021-02-11T22:26:13.472296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.75 accuracy with a standard deviation of 0.09\n",
      "---------- [0.82885906 0.57912458 0.76767677 0.84175084 0.73063973] ---------\n",
      "KNN\n",
      "0.60 accuracy with a standard deviation of 0.17\n",
      "---------- [0.74832215 0.45117845 0.4983165  0.84511785 0.44444444] ---------\n",
      "Decision Tree\n",
      "0.60 accuracy with a standard deviation of 0.21\n",
      "---------- [0.82885906 0.47811448 0.50505051 0.84511785 0.32323232] ---------\n",
      "MLP\n",
      "0.59 accuracy with a standard deviation of 0.14\n",
      "---------- [0.82885906 0.44781145 0.43771044 0.64983165 0.57239057] ---------\n",
      "Ada Boost\n",
      "0.62 accuracy with a standard deviation of 0.14\n",
      "---------- [0.82885906 0.47811448 0.55555556 0.75757576 0.5016835 ] ---------\n",
      "Gaussian NB\n",
      "0.46 accuracy with a standard deviation of 0.13\n",
      "---------- [0.61744966 0.36363636 0.35690236 0.32659933 0.61952862] ---------\n",
      "Quadratic Discriminant Analysis\n",
      "0.60 accuracy with a standard deviation of 0.14\n",
      "---------- [0.64765101 0.45791246 0.48148148 0.84511785 0.58585859] ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "target = (df['Herbicide']) > 0\n",
    "full_cross_validation(X, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1.5 - Others pesticides presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:26:23.082398Z",
     "start_time": "2021-02-11T22:26:18.431737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.85 accuracy with a standard deviation of 0.07\n",
      "---------- [0.90268456 0.82491582 0.72727273 0.90572391 0.9023569 ] ---------\n",
      "KNN\n",
      "0.66 accuracy with a standard deviation of 0.16\n",
      "---------- [0.68791946 0.66329966 0.38720539 0.67676768 0.9023569 ] ---------\n",
      "Decision Tree\n",
      "0.77 accuracy with a standard deviation of 0.16\n",
      "---------- [0.90268456 0.76430976 0.46801347 0.79124579 0.9023569 ] ---------\n",
      "MLP\n",
      "0.70 accuracy with a standard deviation of 0.12\n",
      "---------- [0.77516779 0.62626263 0.49158249 0.83164983 0.77777778] ---------\n",
      "Ada Boost\n",
      "0.73 accuracy with a standard deviation of 0.17\n",
      "---------- [0.90268456 0.66329966 0.43097643 0.79124579 0.84848485] ---------\n",
      "Gaussian NB\n",
      "0.44 accuracy with a standard deviation of 0.20\n",
      "---------- [0.62751678 0.65656566 0.09427609 0.40740741 0.42760943] ---------\n",
      "Quadratic Discriminant Analysis\n",
      "0.76 accuracy with a standard deviation of 0.17\n",
      "---------- [0.90268456 0.65656566 0.47138047 0.86531987 0.90909091] ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "target = (df['Other_pesticides']) > 0\n",
    "full_cross_validation(X, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Over LMR or Not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2.1 - Global pesticide LMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:26:28.380685Z",
     "start_time": "2021-02-11T22:26:23.090819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.81 accuracy with a standard deviation of 0.02\n",
      "---------- [0.80536913 0.81481481 0.83164983 0.78114478 0.82491582] ---------\n",
      "KNN\n",
      "0.59 accuracy with a standard deviation of 0.19\n",
      "---------- [0.80536913 0.46464646 0.2996633  0.62289562 0.75420875] ---------\n",
      "Decision Tree\n",
      "0.77 accuracy with a standard deviation of 0.05\n",
      "---------- [0.80536913 0.81481481 0.70707071 0.71043771 0.82491582] ---------\n",
      "MLP\n",
      "0.48 accuracy with a standard deviation of 0.11\n",
      "---------- [0.38926174 0.61616162 0.36363636 0.42424242 0.61616162] ---------\n",
      "Ada Boost\n",
      "0.60 accuracy with a standard deviation of 0.19\n",
      "---------- [0.68456376 0.64646465 0.25252525 0.62289562 0.8047138 ] ---------\n",
      "Gaussian NB\n",
      "0.57 accuracy with a standard deviation of 0.17\n",
      "---------- [0.77516779 0.45454545 0.30639731 0.69360269 0.63973064] ---------\n",
      "Quadratic Discriminant Analysis\n",
      "0.64 accuracy with a standard deviation of 0.19\n",
      "---------- [0.79865772 0.56902357 0.31313131 0.72390572 0.8047138 ] ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "target = (df['LMR_Fungicide'] + df['LMR_Insecticide'] + df['LMR_Herbicide'] + df['LMR_Other_pesticides']) > 0\n",
    "full_cross_validation(X, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2.2 - Fungicide LMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:26:33.321959Z",
     "start_time": "2021-02-11T22:26:28.393070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.81 accuracy with a standard deviation of 0.05\n",
      "---------- [0.81879195 0.71043771 0.87542088 0.81818182 0.82154882] ---------\n",
      "KNN\n",
      "0.60 accuracy with a standard deviation of 0.20\n",
      "---------- [0.81879195 0.4040404  0.31313131 0.65993266 0.78787879] ---------\n",
      "Decision Tree\n",
      "0.64 accuracy with a standard deviation of 0.21\n",
      "---------- [0.81879195 0.70707071 0.26262626 0.59259259 0.82154882] ---------\n",
      "MLP\n",
      "0.53 accuracy with a standard deviation of 0.19\n",
      "---------- [0.73825503 0.53198653 0.31986532 0.3030303  0.73737374] ---------\n",
      "Ada Boost\n",
      "0.63 accuracy with a standard deviation of 0.25\n",
      "---------- [0.81879195 0.58585859 0.16498316 0.74747475 0.82154882] ---------\n",
      "Gaussian NB\n",
      "0.57 accuracy with a standard deviation of 0.12\n",
      "---------- [0.58724832 0.48484848 0.38383838 0.72390572 0.66329966] ---------\n",
      "Quadratic Discriminant Analysis\n",
      "0.63 accuracy with a standard deviation of 0.24\n",
      "---------- [0.7852349  0.55555556 0.1986532  0.78451178 0.83838384] ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "target = (df['LMR_Fungicide']) > 0\n",
    "full_cross_validation(X, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2.3 - Insecticide LMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:26:38.652918Z",
     "start_time": "2021-02-11T22:26:33.347047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.95 accuracy with a standard deviation of 0.04\n",
      "---------- [0.97315436 0.87878788 0.97643098 0.97306397 0.97306397] ---------\n",
      "KNN\n",
      "0.86 accuracy with a standard deviation of 0.13\n",
      "---------- [0.97315436 0.63973064 0.7979798  0.97643098 0.91919192] ---------\n",
      "Decision Tree\n",
      "0.91 accuracy with a standard deviation of 0.07\n",
      "---------- [0.97315436 0.85521886 0.7979798  0.97306397 0.93939394] ---------\n",
      "MLP\n",
      "0.85 accuracy with a standard deviation of 0.10\n",
      "---------- [0.97315436 0.73737374 0.77777778 0.97306397 0.76767677] ---------\n",
      "Ada Boost\n",
      "0.91 accuracy with a standard deviation of 0.07\n",
      "---------- [0.97315436 0.85521886 0.7979798  0.97306397 0.93939394] ---------\n",
      "Gaussian NB\n",
      "0.63 accuracy with a standard deviation of 0.06\n",
      "---------- [0.60402685 0.54545455 0.73400673 0.62962963 0.62289562] ---------\n",
      "Quadratic Discriminant Analysis\n",
      "0.91 accuracy with a standard deviation of 0.08\n",
      "---------- [0.98993289 0.81144781 0.80808081 0.97643098 0.93939394] ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "target = (df['LMR_Insecticide']) > 0\n",
    "full_cross_validation(X, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2.4 - Herbicide LMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:26:44.768532Z",
     "start_time": "2021-02-11T22:26:38.661914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.99 accuracy with a standard deviation of 0.00\n",
      "---------- [0.98322148 0.98653199 0.98653199 0.98653199 0.98316498] ---------\n",
      "KNN\n",
      "0.92 accuracy with a standard deviation of 0.13\n",
      "---------- [1.         0.94949495 0.67003367 0.98653199 0.98316498] ---------\n",
      "Decision Tree\n",
      "0.92 accuracy with a standard deviation of 0.08\n",
      "---------- [0.98322148 0.98653199 0.78114478 0.98653199 0.88215488] ---------\n",
      "MLP\n",
      "0.89 accuracy with a standard deviation of 0.09\n",
      "---------- [0.98322148 0.98653199 0.79124579 0.79461279 0.91245791] ---------\n",
      "Ada Boost\n",
      "0.94 accuracy with a standard deviation of 0.06\n",
      "---------- [0.98322148 0.98653199 0.84511785 0.98653199 0.88215488] ---------\n",
      "Gaussian NB\n",
      "0.60 accuracy with a standard deviation of 0.14\n",
      "---------- [0.76174497 0.37710438 0.72390572 0.54545455 0.61616162] ---------\n",
      "Quadratic Discriminant Analysis\n",
      "0.99 accuracy with a standard deviation of 0.00\n",
      "---------- [0.98322148 0.98653199 0.98653199 0.98653199 0.98316498] ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "target = (df['LMR_Herbicide']) > 0\n",
    "full_cross_validation(X, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2.5 - Others pesticides LMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:26:49.835891Z",
     "start_time": "2021-02-11T22:26:44.779752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.93 accuracy with a standard deviation of 0.08\n",
      "---------- [0.98322148 0.98653199 0.79124579 0.91245791 0.98316498] ---------\n",
      "KNN\n",
      "0.86 accuracy with a standard deviation of 0.14\n",
      "---------- [0.98322148 0.61616162 0.79124579 0.91245791 0.98316498] ---------\n",
      "Decision Tree\n",
      "0.89 accuracy with a standard deviation of 0.07\n",
      "---------- [0.98322148 0.84511785 0.79124579 0.87205387 0.94949495] ---------\n",
      "MLP\n",
      "0.84 accuracy with a standard deviation of 0.10\n",
      "---------- [0.98322148 0.84511785 0.73400673 0.91245791 0.72390572] ---------\n",
      "Ada Boost\n",
      "0.88 accuracy with a standard deviation of 0.07\n",
      "---------- [0.98322148 0.84511785 0.79124579 0.87205387 0.92592593] ---------\n",
      "Gaussian NB\n",
      "0.53 accuracy with a standard deviation of 0.22\n",
      "---------- [0.59395973 0.72727273 0.11111111 0.69023569 0.53872054] ---------\n",
      "Quadratic Discriminant Analysis\n",
      "0.79 accuracy with a standard deviation of 0.39\n",
      "---------- [0.01677852 0.98653199 0.98653199 0.98653199 0.98316498] ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "target = (df['LMR_Other_pesticides']) > 0\n",
    "full_cross_validation(X, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heavy Metal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T19:11:33.939617Z",
     "start_time": "2021-02-11T19:11:33.935709Z"
    }
   },
   "source": [
    "## 1. Presence or Not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1.1 Mercury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:26:54.932615Z",
     "start_time": "2021-02-11T22:26:49.841118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.84 accuracy with a standard deviation of 0.10\n",
      "---------- [0.94295302 0.71380471 0.75084175 0.86868687 0.94276094] ---------\n",
      "KNN\n",
      "0.69 accuracy with a standard deviation of 0.26\n",
      "---------- [0.95973154 0.77777778 0.36026936 0.3973064  0.94276094] ---------\n",
      "Decision Tree\n",
      "0.80 accuracy with a standard deviation of 0.18\n",
      "---------- [0.94295302 0.83164983 0.46801347 0.83501684 0.94276094] ---------\n",
      "MLP\n",
      "0.82 accuracy with a standard deviation of 0.08\n",
      "---------- [0.72818792 0.95286195 0.8047138  0.83838384 0.76767677] ---------\n",
      "Ada Boost\n",
      "0.77 accuracy with a standard deviation of 0.12\n",
      "---------- [0.77516779 0.90909091 0.75084175 0.55555556 0.84511785] ---------\n",
      "Gaussian NB\n",
      "0.23 accuracy with a standard deviation of 0.17\n",
      "---------- [0.55369128 0.09090909 0.21212121 0.14814815 0.12794613] ---------\n",
      "Quadratic Discriminant Analysis\n",
      "0.88 accuracy with a standard deviation of 0.09\n",
      "---------- [0.95973154 0.87542088 0.70707071 0.87542088 0.96296296] ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "target = df['Presence_Mercury']\n",
    "full_cross_validation(X, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LMR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2.1 Global LMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:27:01.624131Z",
     "start_time": "2021-02-11T22:26:54.960972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96 accuracy with a standard deviation of 0.01\n",
      "---------- [0.96308725 0.96632997 0.96632997 0.96296296 0.94612795] ---------\n",
      "KNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70 accuracy with a standard deviation of 0.18\n",
      "---------- [0.82214765 0.76094276 0.43771044 0.55555556 0.94612795] ---------\n",
      "Decision Tree\n",
      "0.78 accuracy with a standard deviation of 0.11\n",
      "---------- [0.66442953 0.76094276 0.66666667 0.86195286 0.94949495] ---------\n",
      "MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59 accuracy with a standard deviation of 0.16\n",
      "---------- [0.30872483 0.67340067 0.53198653 0.61952862 0.79461279] ---------\n",
      "Ada Boost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91 accuracy with a standard deviation of 0.12\n",
      "---------- [0.66442953 0.96632997 0.96632997 0.96632997 0.96632997] ---------\n",
      "Gaussian NB\n",
      "0.37 accuracy with a standard deviation of 0.18\n",
      "---------- [0.09060403 0.54882155 0.57912458 0.28282828 0.35353535] ---------\n",
      "Quadratic Discriminant Analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan accuracy with a standard deviation of nan\n",
      "---------- [0.0033557         nan        nan 0.01683502 0.003367  ] ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 708, in fit\n",
      "    raise ValueError('y has only 1 sample in class %s, covariance '\n",
      "ValueError: y has only 1 sample in class FalseFalseTrueFalseFalse, covariance is ill defined.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 708, in fit\n",
      "    raise ValueError('y has only 1 sample in class %s, covariance '\n",
      "ValueError: y has only 1 sample in class FalseFalseTrueFalseFalse, covariance is ill defined.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n"
     ]
    }
   ],
   "source": [
    "target = (df['Limit_Lead'] + df['Limit_Cadmium'] + df['Limit_Arsenic'] + df['Limit_Mercury'] + df['Limit_Copper'])\n",
    "full_cross_validation(X, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2.2 Lead LMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:27:07.217683Z",
     "start_time": "2021-02-11T22:27:01.650044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.97 accuracy with a standard deviation of 0.01\n",
      "---------- [0.97651007 0.97643098 0.97643098 0.95622896 0.97979798] ---------\n",
      "KNN\n",
      "0.81 accuracy with a standard deviation of 0.19\n",
      "---------- [0.97651007 0.92929293 0.61952862 0.55218855 0.97643098] ---------\n",
      "Decision Tree\n",
      "0.88 accuracy with a standard deviation of 0.10\n",
      "---------- [0.97651007 0.80808081 0.72727273 0.91919192 0.97979798] ---------\n",
      "MLP\n",
      "0.70 accuracy with a standard deviation of 0.23\n",
      "---------- [0.82214765 0.92255892 0.47474747 0.37037037 0.91919192] ---------\n",
      "Ada Boost\n",
      "0.98 accuracy with a standard deviation of 0.00\n",
      "---------- [0.97651007 0.97643098 0.97643098 0.97979798 0.97979798] ---------\n",
      "Gaussian NB\n",
      "0.62 accuracy with a standard deviation of 0.20\n",
      "---------- [0.83221477 0.75084175 0.76767677 0.36363636 0.3973064 ] ---------\n",
      "Quadratic Discriminant Analysis\n",
      "0.01 accuracy with a standard deviation of 0.00\n",
      "---------- [0.01006711 0.00673401 0.00673401 0.01683502 0.01010101] ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n"
     ]
    }
   ],
   "source": [
    "target = df['Limit_Lead']\n",
    "full_cross_validation(X, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2.3 Cadnium LMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:27:13.243911Z",
     "start_time": "2021-02-11T22:27:07.228579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.93 accuracy with a standard deviation of 0.05\n",
      "---------- [0.83221477 0.97643098 0.93602694 0.93602694 0.97643098] ---------\n",
      "KNN\n",
      "0.80 accuracy with a standard deviation of 0.13\n",
      "---------- [0.83221477 0.76767677 0.82828283 0.57239057 0.97643098] ---------\n",
      "Decision Tree\n",
      "0.84 accuracy with a standard deviation of 0.11\n",
      "---------- [0.67449664 0.76767677 0.93602694 0.85858586 0.97643098] ---------\n",
      "MLP\n",
      "0.82 accuracy with a standard deviation of 0.12\n",
      "---------- [0.66442953 0.98316498 0.93602694 0.81818182 0.7037037 ] ---------\n",
      "Ada Boost\n",
      "0.87 accuracy with a standard deviation of 0.12\n",
      "---------- [0.67449664 0.76767677 0.93602694 0.97643098 0.97643098] ---------\n",
      "Gaussian NB\n",
      "0.42 accuracy with a standard deviation of 0.24\n",
      "---------- [0.08053691 0.53872054 0.8013468  0.28956229 0.4006734 ] ---------\n",
      "Quadratic Discriminant Analysis\n",
      "0.40 accuracy with a standard deviation of 0.47\n",
      "---------- [0.01006711 0.97643098 0.97643098 0.00673401 0.00673401] ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n"
     ]
    }
   ],
   "source": [
    "target = df['Limit_Cadmium']\n",
    "full_cross_validation(X, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2.4 Arsenic LMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:27:18.767986Z",
     "start_time": "2021-02-11T22:27:13.259146Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.96 accuracy with a standard deviation of 0.05\n",
      "---------- [0.98322148 0.98316498 0.98316498 0.86195286 0.98316498] ---------\n",
      "KNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 accuracy with a standard deviation of 0.14\n",
      "---------- [0.79530201 0.77441077 0.63299663 0.58585859 0.98316498] ---------\n",
      "Decision Tree\n",
      "0.80 accuracy with a standard deviation of 0.15\n",
      "---------- [0.98322148 0.65319865 0.74074074 0.65993266 0.98316498] ---------\n",
      "MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88 accuracy with a standard deviation of 0.07\n",
      "---------- [0.82885906 0.93602694 0.76767677 0.92929293 0.95286195] ---------\n",
      "Ada Boost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89 accuracy with a standard deviation of 0.20\n",
      "---------- [0.98322148 0.98989899 0.98316498 0.49494949 0.98316498] ---------\n",
      "Gaussian NB\n",
      "0.64 accuracy with a standard deviation of 0.19\n",
      "---------- [0.83221477 0.74410774 0.77777778 0.39393939 0.42760943] ---------\n",
      "Quadratic Discriminant Analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 708, in fit\n",
      "    raise ValueError('y has only 1 sample in class %s, covariance '\n",
      "ValueError: y has only 1 sample in class True, covariance is ill defined.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan accuracy with a standard deviation of nan\n",
      "---------- [       nan 0.         0.         0.01683502        nan] ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 708, in fit\n",
      "    raise ValueError('y has only 1 sample in class %s, covariance '\n",
      "ValueError: y has only 1 sample in class True, covariance is ill defined.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    }
   ],
   "source": [
    "target = df['Limit_Arsenic']\n",
    "full_cross_validation(X, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2.5 Mercury LMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:27:24.093027Z",
     "start_time": "2021-02-11T22:27:18.788001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.97 accuracy with a standard deviation of 0.03\n",
      "---------- [0.98322148 0.98653199 0.98653199 0.90572391 0.98316498] ---------\n",
      "KNN\n",
      "0.79 accuracy with a standard deviation of 0.17\n",
      "---------- [0.98322148 0.77441077 0.63973064 0.57912458 0.98316498] ---------\n",
      "Decision Tree\n",
      "0.92 accuracy with a standard deviation of 0.09\n",
      "---------- [0.98322148 0.77441077 0.98653199 0.86531987 0.98316498] ---------\n",
      "MLP\n",
      "0.82 accuracy with a standard deviation of 0.15\n",
      "---------- [0.98322148 0.79461279 0.61616162 0.7037037  0.98316498] ---------\n",
      "Ada Boost\n",
      "0.89 accuracy with a standard deviation of 0.16\n",
      "---------- [0.98322148 0.93602694 0.98653199 0.57912458 0.98316498] ---------\n",
      "Gaussian NB\n",
      "0.62 accuracy with a standard deviation of 0.21\n",
      "---------- [0.83221477 0.74074074 0.78114478 0.31313131 0.43434343] ---------\n",
      "Quadratic Discriminant Analysis\n",
      "0.98 accuracy with a standard deviation of 0.00\n",
      "---------- [0.98322148 0.98653199 0.98653199 0.98316498 0.98316498] ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "target = df['Limit_Mercury']\n",
    "full_cross_validation(X, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2.6 Cooper LMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-11T22:27:28.861261Z",
     "start_time": "2021-02-11T22:27:24.123662Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "0.97 accuracy with a standard deviation of 0.02\n",
      "---------- [0.97986577 0.92592593 0.97979798 0.98316498 0.96632997] ---------\n",
      "KNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78 accuracy with a standard deviation of 0.17\n",
      "---------- [0.97986577 0.76430976 0.62626263 0.57575758 0.96632997] ---------\n",
      "Decision Tree\n",
      "0.85 accuracy with a standard deviation of 0.14\n",
      "---------- [0.97986577 0.64309764 0.73400673 0.94276094 0.96632997] ---------\n",
      "MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86 accuracy with a standard deviation of 0.13\n",
      "---------- [0.97986577 0.92592593 0.97979798 0.63636364 0.79124579] ---------\n",
      "Ada Boost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86 accuracy with a standard deviation of 0.18\n",
      "---------- [0.97986577 0.98316498 0.82154882 0.98316498 0.51178451] ---------\n",
      "Gaussian NB\n",
      "0.63 accuracy with a standard deviation of 0.19\n",
      "---------- [0.83221477 0.74747475 0.77441077 0.38720539 0.41414141] ---------\n",
      "Quadratic Discriminant Analysis\n",
      "0.00 accuracy with a standard deviation of 0.00\n",
      "---------- [0.0033557 0.        0.        0.003367  0.003367 ] ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:670: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/jeromecoumont/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n"
     ]
    }
   ],
   "source": [
    "target = df['Limit_Copper']\n",
    "full_cross_validation(X, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
